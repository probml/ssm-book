{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: distrax in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (0.0.1)\n",
      "Collecting distrax\n",
      "  Downloading distrax-0.1.2-py3-none-any.whl (272 kB)\n",
      "\u001b[K     |████████████████████████████████| 272 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jax>=0.1.55 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from distrax) (0.2.11)\n",
      "Requirement already satisfied: absl-py>=0.9.0 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from distrax) (0.12.0)\n",
      "Requirement already satisfied: chex>=0.0.7 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from distrax) (0.0.8)\n",
      "Requirement already satisfied: jaxlib>=0.1.67 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from distrax) (0.1.70)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from distrax) (1.19.5)\n",
      "Collecting tensorflow-probability>=0.15.0\n",
      "  Using cached tensorflow_probability-0.16.0-py2.py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from absl-py>=0.9.0->distrax) (1.15.0)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from chex>=0.0.7->distrax) (0.1.6)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from chex>=0.0.7->distrax) (0.11.1)\n",
      "Requirement already satisfied: opt-einsum in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from jax>=0.1.55->distrax) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from jaxlib>=0.1.67->distrax) (1.12)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from jaxlib>=0.1.67->distrax) (1.6.3)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from tensorflow-probability>=0.15.0->distrax) (1.6.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from tensorflow-probability>=0.15.0->distrax) (4.4.2)\n",
      "Requirement already satisfied: gast>=0.3.2 in /opt/anaconda3/envs/spyder-dev/lib/python3.9/site-packages (from tensorflow-probability>=0.15.0->distrax) (0.4.0)\n",
      "Installing collected packages: tensorflow-probability, distrax\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.13.0\n",
      "    Uninstalling tensorflow-probability-0.13.0:\n",
      "      Successfully uninstalled tensorflow-probability-0.13.0\n",
      "  Attempting uninstall: distrax\n",
      "    Found existing installation: distrax 0.0.1\n",
      "    Uninstalling distrax-0.0.1:\n",
      "      Successfully uninstalled distrax-0.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jsl 0.0.0 requires dataclasses, which is not installed.\u001b[0m\n",
      "Successfully installed distrax-0.1.2 tensorflow-probability-0.16.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/anaconda3/envs/spyder-dev/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# meta-data does not work yet in VScode\n",
    "# https://github.com/microsoft/vscode-jupyter/issues/1121\n",
    "\n",
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-cell\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "### Install necessary libraries\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "except:\n",
    "    # For cuda version, see https://github.com/google/jax#installation\n",
    "    %pip install --upgrade \"jax[cpu]\" \n",
    "    import jax\n",
    "\n",
    "try:\n",
    "    import distrax\n",
    "except:\n",
    "    %pip install --upgrade  distrax\n",
    "    import distrax\n",
    "\n",
    "try:\n",
    "    import jsl\n",
    "except:\n",
    "    %pip install git+https://github.com/probml/jsl\n",
    "    import jsl\n",
    "\n",
    "try:\n",
    "    import rich\n",
    "except:\n",
    "    %pip install rich\n",
    "    import rich\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-cell\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "### Import standard libraries\n",
    "\n",
    "import abc\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "from typing import Any, Callable, NamedTuple, Optional, Union, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax, vmap, jit, grad\n",
    "from jax.scipy.special import logit\n",
    "from jax.nn import softmax\n",
    "from functools import partial\n",
    "from jax.random import PRNGKey, split\n",
    "\n",
    "import inspect\n",
    "import inspect as py_inspect\n",
    "import rich\n",
    "from rich import inspect as r_inspect\n",
    "from rich import print as r_print\n",
    "\n",
    "def print_source(fname):\n",
    "    r_print(py_inspect.getsource(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{math}\n",
    "\n",
    "\\newcommand\\floor[1]{\\lfloor#1\\rfloor}\n",
    "\n",
    "\\newcommand{\\real}{\\mathbb{R}}\n",
    "\n",
    "% Numbers\n",
    "\\newcommand{\\vzero}{\\boldsymbol{0}}\n",
    "\\newcommand{\\vone}{\\boldsymbol{1}}\n",
    "\n",
    "% Greek https://www.latex-tutorial.com/symbols/greek-alphabet/\n",
    "\\newcommand{\\valpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\vbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\vchi}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\vdelta}{\\boldsymbol{\\delta}}\n",
    "\\newcommand{\\vDelta}{\\boldsymbol{\\Delta}}\n",
    "\\newcommand{\\vepsilon}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\vzeta}{\\boldsymbol{\\zeta}}\n",
    "\\newcommand{\\vXi}{\\boldsymbol{\\Xi}}\n",
    "\\newcommand{\\vell}{\\boldsymbol{\\ell}}\n",
    "\\newcommand{\\veta}{\\boldsymbol{\\eta}}\n",
    "%\\newcommand{\\vEta}{\\boldsymbol{\\Eta}}\n",
    "\\newcommand{\\vgamma}{\\boldsymbol{\\gamma}}\n",
    "\\newcommand{\\vGamma}{\\boldsymbol{\\Gamma}}\n",
    "\\newcommand{\\vmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\vmut}{\\boldsymbol{\\tilde{\\mu}}}\n",
    "\\newcommand{\\vnu}{\\boldsymbol{\\nu}}\n",
    "\\newcommand{\\vkappa}{\\boldsymbol{\\kappa}}\n",
    "\\newcommand{\\vlambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\vLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\vLambdaBar}{\\overline{\\vLambda}}\n",
    "%\\newcommand{\\vnu}{\\boldsymbol{\\nu}}\n",
    "\\newcommand{\\vomega}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\vOmega}{\\boldsymbol{\\Omega}}\n",
    "\\newcommand{\\vphi}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\vvarphi}{\\boldsymbol{\\varphi}}\n",
    "\\newcommand{\\vPhi}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\vpi}{\\boldsymbol{\\pi}}\n",
    "\\newcommand{\\vPi}{\\boldsymbol{\\Pi}}\n",
    "\\newcommand{\\vpsi}{\\boldsymbol{\\psi}}\n",
    "\\newcommand{\\vPsi}{\\boldsymbol{\\Psi}}\n",
    "\\newcommand{\\vrho}{\\boldsymbol{\\rho}}\n",
    "\\newcommand{\\vtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\vthetat}{\\boldsymbol{\\tilde{\\theta}}}\n",
    "\\newcommand{\\vTheta}{\\boldsymbol{\\Theta}}\n",
    "\\newcommand{\\vsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\vSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\vSigmat}{\\boldsymbol{\\tilde{\\Sigma}}}\n",
    "\\newcommand{\\vsigmoid}{\\vsigma}\n",
    "\\newcommand{\\vtau}{\\boldsymbol{\\tau}}\n",
    "\\newcommand{\\vxi}{\\boldsymbol{\\xi}}\n",
    "\n",
    "\n",
    "% Lower Roman (Vectors)\n",
    "\\newcommand{\\va}{\\mathbf{a}}\n",
    "\\newcommand{\\vb}{\\mathbf{b}}\n",
    "\\newcommand{\\vBt}{\\mathbf{\\tilde{B}}}\n",
    "\\newcommand{\\vc}{\\mathbf{c}}\n",
    "\\newcommand{\\vct}{\\mathbf{\\tilde{c}}}\n",
    "\\newcommand{\\vd}{\\mathbf{d}}\n",
    "\\newcommand{\\ve}{\\mathbf{e}}\n",
    "\\newcommand{\\vf}{\\mathbf{f}}\n",
    "\\newcommand{\\vg}{\\mathbf{g}}\n",
    "\\newcommand{\\vh}{\\mathbf{h}}\n",
    "%\\newcommand{\\myvh}{\\mathbf{h}}\n",
    "\\newcommand{\\vi}{\\mathbf{i}}\n",
    "\\newcommand{\\vj}{\\mathbf{j}}\n",
    "\\newcommand{\\vk}{\\mathbf{k}}\n",
    "\\newcommand{\\vl}{\\mathbf{l}}\n",
    "\\newcommand{\\vm}{\\mathbf{m}}\n",
    "\\newcommand{\\vn}{\\mathbf{n}}\n",
    "\\newcommand{\\vo}{\\mathbf{o}}\n",
    "\\newcommand{\\vp}{\\mathbf{p}}\n",
    "\\newcommand{\\vq}{\\mathbf{q}}\n",
    "\\newcommand{\\vr}{\\mathbf{r}}\n",
    "\\newcommand{\\vs}{\\mathbf{s}}\n",
    "\\newcommand{\\vt}{\\mathbf{t}}\n",
    "\\newcommand{\\vu}{\\mathbf{u}}\n",
    "\\newcommand{\\vv}{\\mathbf{v}}\n",
    "\\newcommand{\\vw}{\\mathbf{w}}\n",
    "\\newcommand{\\vws}{\\vw_s}\n",
    "\\newcommand{\\vwt}{\\mathbf{\\tilde{w}}}\n",
    "\\newcommand{\\vWt}{\\mathbf{\\tilde{W}}}\n",
    "\\newcommand{\\vwh}{\\hat{\\vw}}\n",
    "\\newcommand{\\vx}{\\mathbf{x}}\n",
    "%\\newcommand{\\vx}{\\mathbf{x}}\n",
    "\\newcommand{\\vxt}{\\mathbf{\\tilde{x}}}\n",
    "\\newcommand{\\vy}{\\mathbf{y}}\n",
    "\\newcommand{\\vyt}{\\mathbf{\\tilde{y}}}\n",
    "\\newcommand{\\vz}{\\mathbf{z}}\n",
    "%\\newcommand{\\vzt}{\\mathbf{\\tilde{z}}}\n",
    "\n",
    "\n",
    "% Upper Roman (Matrices)\n",
    "\\newcommand{\\vA}{\\mathbf{A}}\n",
    "\\newcommand{\\vB}{\\mathbf{B}}\n",
    "\\newcommand{\\vC}{\\mathbf{C}}\n",
    "\\newcommand{\\vD}{\\mathbf{D}}\n",
    "\\newcommand{\\vE}{\\mathbf{E}}\n",
    "\\newcommand{\\vF}{\\mathbf{F}}\n",
    "\\newcommand{\\vG}{\\mathbf{G}}\n",
    "\\newcommand{\\vH}{\\mathbf{H}}\n",
    "\\newcommand{\\vI}{\\mathbf{I}}\n",
    "\\newcommand{\\vJ}{\\mathbf{J}}\n",
    "\\newcommand{\\vK}{\\mathbf{K}}\n",
    "\\newcommand{\\vL}{\\mathbf{L}}\n",
    "\\newcommand{\\vM}{\\mathbf{M}}\n",
    "\\newcommand{\\vMt}{\\mathbf{\\tilde{M}}}\n",
    "\\newcommand{\\vN}{\\mathbf{N}}\n",
    "\\newcommand{\\vO}{\\mathbf{O}}\n",
    "\\newcommand{\\vP}{\\mathbf{P}}\n",
    "\\newcommand{\\vQ}{\\mathbf{Q}}\n",
    "\\newcommand{\\vR}{\\mathbf{R}}\n",
    "\\newcommand{\\vS}{\\mathbf{S}}\n",
    "\\newcommand{\\vT}{\\mathbf{T}}\n",
    "\\newcommand{\\vU}{\\mathbf{U}}\n",
    "\\newcommand{\\vV}{\\mathbf{V}}\n",
    "\\newcommand{\\vW}{\\mathbf{W}}\n",
    "\\newcommand{\\vX}{\\mathbf{X}}\n",
    "%\\newcommand{\\vXs}{\\vX_{\\vs}}\n",
    "\\newcommand{\\vXs}{\\vX_{s}}\n",
    "\\newcommand{\\vXt}{\\mathbf{\\tilde{X}}}\n",
    "\\newcommand{\\vY}{\\mathbf{Y}}\n",
    "\\newcommand{\\vZ}{\\mathbf{Z}}\n",
    "\\newcommand{\\vZt}{\\mathbf{\\tilde{Z}}}\n",
    "\\newcommand{\\vzt}{\\mathbf{\\tilde{z}}}\n",
    "\n",
    "\n",
    "%%%%\n",
    "\\newcommand{\\hidden}{\\vz}\n",
    "\\newcommand{\\obs}{\\vy}\n",
    "\\newcommand{\\inputs}{\\vu}\n",
    "\\newcommand{\\input}{\\inputs}\n",
    "\n",
    "\\newcommand{\\hmmTrans}{\\vA}\n",
    "\\newcommand{\\hmmObs}{\\vB}\n",
    "\\newcommand{\\hmmInit}{\\vpi}\n",
    "\\newcommand{\\hmmhid}{\\hidden}\n",
    "\\newcommand{\\hmmobs}{\\obs}\n",
    "\n",
    "\\newcommand{\\ldsDyn}{\\vA}\n",
    "\\newcommand{\\ldsObs}{\\vC}\n",
    "\\newcommand{\\ldsDynIn}{\\vB}\n",
    "\\newcommand{\\ldsObsIn}{\\vD}\n",
    "\\newcommand{\\ldsDynNoise}{\\vQ}\n",
    "\\newcommand{\\ldsObsNoise}{\\vR}\n",
    "\n",
    "\\newcommand{\\ssmDyn}{f}\n",
    "\\newcommand{\\ssmObs}{h}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:ssm-intro)=\n",
    "# What are State Space Models?\n",
    "\n",
    "\n",
    "A state space model or SSM\n",
    "is a partially observed Markov model,\n",
    "in which the hidden state,  $\\hidden_t$,\n",
    "evolves over time according to a Markov process,\n",
    "possibly conditional on external inputs or controls $\\input_t$,\n",
    "and each hidden state generates some\n",
    "observations $\\obs_t$ at each time step.\n",
    "(In this book, we mostly focus on discrete time systems,\n",
    "although  we consider the continuous-time case in  XXX.)\n",
    "We get to see the observations, but not the hidden state.\n",
    "Our main goal is to infer the hidden state given the observations.\n",
    "However, we can also use the model to predict future observations,\n",
    "by first predicting future hidden states, and then predicting\n",
    "what observations they might generate.\n",
    "By using  a hidden state $\\hidden_t$\n",
    "to represent the past observations, $\\obs_{1:t-1}$,\n",
    "the  model can have ``infinite'' memory,\n",
    "unlike a standard Markov model.\n",
    "\n",
    "Formally we can define an SSM \n",
    "as the following joint distribution:\n",
    "```{math}\n",
    ":label: SSMfull\n",
    "p(\\hmmobs_{1:T},\\hmmhid_{1:T}|\\inputs_{1:T})\n",
    " = \\left[ p(\\hmmhid_1|\\inputs_1) \\prod_{t=2}^{T}\n",
    " p(\\hmmhid_t|\\hmmhid_{t-1},\\inputs_t) \\right]\n",
    " \\left[ \\prod_{t=1}^T p(\\hmmobs_t|\\hmmhid_t, \\inputs_t, \\hmmobs_{t-1}) \\right]\n",
    "```\n",
    "where $p(\\hmmhid_t|\\hmmhid_{t-1},\\inputs_t)$ is the\n",
    "transition model,\n",
    "$p(\\hmmobs_t|\\hmmhid_t, \\inputs_t, \\hmmobs_{t-1})$ is the\n",
    "observation model,\n",
    "and $\\inputs_{t}$ is an optional input or action.\n",
    "See {numref}`Figure %s <ssm-ar>` \n",
    "for an illustration of the corresponding graphical model.\n",
    "\n",
    "\n",
    "```{figure} /figures/SSM-AR-inputs.png\n",
    ":scale: 100%\n",
    ":name: ssm-ar\n",
    "\n",
    "Illustration of an SSM as a graphical model.\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often consider a simpler setting in which there\n",
    "are no external inputs,\n",
    "and the observations are conditionally independent of each other\n",
    "(rather than having Markovian dependencies) given the hidden state.\n",
    "In this case the joint simplifies to \n",
    "```{math}\n",
    ":label: SSMsimplified\n",
    "p(\\hmmobs_{1:T},\\hmmhid_{1:T})\n",
    " = \\left[ p(\\hmmhid_1) \\prod_{t=2}^{T}\n",
    " p(\\hmmhid_t|\\hmmhid_{t-1}) \\right]\n",
    " \\left[ \\prod_{t=1}^T p(\\hmmobs_t|\\hmmhid_t \\right]\n",
    "```\n",
    "See {numref}`Figure %s <ssm-simplified>` \n",
    "for an illustration of the corresponding graphical model.\n",
    "Compare {eq}`SSMfull` and {eq}`SSMsimplified`.\n",
    "\n",
    "\n",
    "```{figure} /figures/SSM-simplified.png\n",
    ":scale: 100%\n",
    ":name: ssm-simplified\n",
    "\n",
    "Illustration of a simplified SSM.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:hmm-intro)=\n",
    "# Hidden Markov Models\n",
    "\n",
    "In this section, we discuss the\n",
    "hidden Markov model or HMM,\n",
    "which is a state space model in which the hidden states\n",
    "are discrete, so $\\hmmhid_t \\in \\{1,\\ldots, K\\}$.\n",
    "The observations may be discrete,\n",
    "$\\hmmobs_t \\in \\{1,\\ldots, C\\}$,\n",
    "or continuous,\n",
    "$\\hmmobs_t \\in \\real^D$,\n",
    "or some combination,\n",
    "as we illustrate below.\n",
    "More details can be found in e.g., \n",
    "{cite}`Rabiner89,Fraser08,Cappe05`.\n",
    "For an interactive introduction,\n",
    "see https://nipunbatra.github.io/hmm/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:casino-ex)=\n",
    "### Example: Casino HMM\n",
    "\n",
    "To illustrate HMMs with categorical observation model,\n",
    "we consider the \"Ocassionally dishonest casino\" model from {cite}`Durbin98`.\n",
    "There are 2 hidden states, representing whether the dice being used in the casino is fair or loaded.\n",
    "Each state defines a distribution over the 6 possible observations.\n",
    "\n",
    "The transition model is denoted by\n",
    "```{math}\n",
    "p(z_t=j|z_{t-1}=i) = \\hmmTrans_{ij}\n",
    "```\n",
    "Here the $i$'th row of $\\vA$ corresponds to the outgoing distribution from state $i$.\n",
    "This is  a row stochastic matrix,\n",
    "meaning each row sums to one.\n",
    "We can visualize\n",
    "the non-zero entries in the transition matrix by creating a state transition diagram,\n",
    "as shown in \n",
    "{numref}`Figure %s <casino-fig>`\n",
    "%{ref}`casino-fig`.\n",
    "\n",
    "```{figure} /figures/casino.png\n",
    ":scale: 50%\n",
    ":name: casino-fig\n",
    "\n",
    "Illustration of the casino HMM.\n",
    "```\n",
    "\n",
    "The  observation model\n",
    "$p(\\obs_t|\\hidden_t=j)$ has the form\n",
    "```{math}\n",
    "p(\\obs_t=k|\\hidden_t=j) = \\hmmObs_{jk} \n",
    "```\n",
    "This is represented by the histograms associated with each\n",
    "state in {ref}`casino-fig`.\n",
    "\n",
    "Finally,\n",
    "the initial state distribution is denoted by\n",
    "```{math}\n",
    "p(z_1=j) = \\hmmInit_j\n",
    "```\n",
    "\n",
    "Collectively we denote all the parameters by $\\vtheta=(\\hmmTrans, \\hmmObs, \\hmmInit)$.\n",
    "\n",
    "Now let us implement this model in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state transition matrix\n",
    "A = np.array([\n",
    "    [0.95, 0.05],\n",
    "    [0.10, 0.90]\n",
    "])\n",
    "\n",
    "# observation matrix\n",
    "B = np.array([\n",
    "    [1/6, 1/6, 1/6, 1/6, 1/6, 1/6], # fair die\n",
    "    [1/10, 1/10, 1/10, 1/10, 1/10, 5/10] # loaded die\n",
    "])\n",
    "\n",
    "pi = np.array([0.5, 0.5])\n",
    "\n",
    "(nstates, nobs) = np.shape(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<distrax._src.utils.hmm.HMM object at 0x7fd6619b4700>\n"
     ]
    }
   ],
   "source": [
    "import distrax\n",
    "from distrax import HMM\n",
    "\n",
    "\n",
    "hmm = HMM(trans_dist=distrax.Categorical(probs=A),\n",
    "            init_dist=distrax.Categorical(probs=pi),\n",
    "            obs_dist=distrax.Categorical(probs=B))\n",
    "\n",
    "print(hmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample from the model. We will generate a sequence of latent states, $\\hid_{1:T}$,\n",
    "which we then convert to a sequence of observations, $\\obs_{1:T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing sample observed/latent...\n",
      "x: 633665342652353616444236412331351246651613325161656366246242\n",
      "z: 222222211111111111111111111111111111111222111111112222211111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "seed = 314\n",
    "n_samples = 300\n",
    "z_hist, x_hist = hmm.sample(seed=PRNGKey(seed), seq_len=n_samples)\n",
    "\n",
    "z_hist_str = \"\".join((np.array(z_hist) + 1).astype(str))[:60]\n",
    "x_hist_str = \"\".join((np.array(x_hist) + 1).astype(str))[:60]\n",
    "\n",
    "print(\"Printing sample observed/latent...\")\n",
    "print(f\"x: {x_hist_str}\")\n",
    "print(f\"z: {z_hist_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our primary goal will be to infer the latent state from the observations,\n",
    "so we can detect if the casino is being dishonest or not. This will\n",
    "affect how we choose to gamble our money.\n",
    "We discuss various ways to perform this inference below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Gaussian SSMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
