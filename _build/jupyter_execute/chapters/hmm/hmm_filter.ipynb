{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{math}\n",
    "\n",
    "\\newcommand{\\defeq}{\\triangleq}\n",
    "\\newcommand{\\trans}{{\\mkern-1.5mu\\mathsf{T}}}\n",
    "\\newcommand{\\transpose}[1]{{#1}^{\\trans}}\n",
    "\n",
    "\\newcommand{\\inv}[1]{{#1}^{-1}}\n",
    "\\DeclareMathOperator{\\dotstar}{\\odot}\n",
    "\n",
    "\n",
    "\\newcommand\\floor[1]{\\lfloor#1\\rfloor}\n",
    "\n",
    "\\newcommand{\\real}{\\mathbb{R}}\n",
    "\n",
    "% Numbers\n",
    "\\newcommand{\\vzero}{\\boldsymbol{0}}\n",
    "\\newcommand{\\vone}{\\boldsymbol{1}}\n",
    "\n",
    "% Greek https://www.latex-tutorial.com/symbols/greek-alphabet/\n",
    "\\newcommand{\\valpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\vbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\vchi}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\vdelta}{\\boldsymbol{\\delta}}\n",
    "\\newcommand{\\vDelta}{\\boldsymbol{\\Delta}}\n",
    "\\newcommand{\\vepsilon}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\vzeta}{\\boldsymbol{\\zeta}}\n",
    "\\newcommand{\\vXi}{\\boldsymbol{\\Xi}}\n",
    "\\newcommand{\\vell}{\\boldsymbol{\\ell}}\n",
    "\\newcommand{\\veta}{\\boldsymbol{\\eta}}\n",
    "%\\newcommand{\\vEta}{\\boldsymbol{\\Eta}}\n",
    "\\newcommand{\\vgamma}{\\boldsymbol{\\gamma}}\n",
    "\\newcommand{\\vGamma}{\\boldsymbol{\\Gamma}}\n",
    "\\newcommand{\\vmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\vmut}{\\boldsymbol{\\tilde{\\mu}}}\n",
    "\\newcommand{\\vnu}{\\boldsymbol{\\nu}}\n",
    "\\newcommand{\\vkappa}{\\boldsymbol{\\kappa}}\n",
    "\\newcommand{\\vlambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\vLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\vLambdaBar}{\\overline{\\vLambda}}\n",
    "%\\newcommand{\\vnu}{\\boldsymbol{\\nu}}\n",
    "\\newcommand{\\vomega}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\vOmega}{\\boldsymbol{\\Omega}}\n",
    "\\newcommand{\\vphi}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\vvarphi}{\\boldsymbol{\\varphi}}\n",
    "\\newcommand{\\vPhi}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\vpi}{\\boldsymbol{\\pi}}\n",
    "\\newcommand{\\vPi}{\\boldsymbol{\\Pi}}\n",
    "\\newcommand{\\vpsi}{\\boldsymbol{\\psi}}\n",
    "\\newcommand{\\vPsi}{\\boldsymbol{\\Psi}}\n",
    "\\newcommand{\\vrho}{\\boldsymbol{\\rho}}\n",
    "\\newcommand{\\vtheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\vthetat}{\\boldsymbol{\\tilde{\\theta}}}\n",
    "\\newcommand{\\vTheta}{\\boldsymbol{\\Theta}}\n",
    "\\newcommand{\\vsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\vSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\vSigmat}{\\boldsymbol{\\tilde{\\Sigma}}}\n",
    "\\newcommand{\\vsigmoid}{\\vsigma}\n",
    "\\newcommand{\\vtau}{\\boldsymbol{\\tau}}\n",
    "\\newcommand{\\vxi}{\\boldsymbol{\\xi}}\n",
    "\n",
    "\n",
    "% Lower Roman (Vectors)\n",
    "\\newcommand{\\va}{\\mathbf{a}}\n",
    "\\newcommand{\\vb}{\\mathbf{b}}\n",
    "\\newcommand{\\vBt}{\\mathbf{\\tilde{B}}}\n",
    "\\newcommand{\\vc}{\\mathbf{c}}\n",
    "\\newcommand{\\vct}{\\mathbf{\\tilde{c}}}\n",
    "\\newcommand{\\vd}{\\mathbf{d}}\n",
    "\\newcommand{\\ve}{\\mathbf{e}}\n",
    "\\newcommand{\\vf}{\\mathbf{f}}\n",
    "\\newcommand{\\vg}{\\mathbf{g}}\n",
    "\\newcommand{\\vh}{\\mathbf{h}}\n",
    "%\\newcommand{\\myvh}{\\mathbf{h}}\n",
    "\\newcommand{\\vi}{\\mathbf{i}}\n",
    "\\newcommand{\\vj}{\\mathbf{j}}\n",
    "\\newcommand{\\vk}{\\mathbf{k}}\n",
    "\\newcommand{\\vl}{\\mathbf{l}}\n",
    "\\newcommand{\\vm}{\\mathbf{m}}\n",
    "\\newcommand{\\vn}{\\mathbf{n}}\n",
    "\\newcommand{\\vo}{\\mathbf{o}}\n",
    "\\newcommand{\\vp}{\\mathbf{p}}\n",
    "\\newcommand{\\vq}{\\mathbf{q}}\n",
    "\\newcommand{\\vr}{\\mathbf{r}}\n",
    "\\newcommand{\\vs}{\\mathbf{s}}\n",
    "\\newcommand{\\vt}{\\mathbf{t}}\n",
    "\\newcommand{\\vu}{\\mathbf{u}}\n",
    "\\newcommand{\\vv}{\\mathbf{v}}\n",
    "\\newcommand{\\vw}{\\mathbf{w}}\n",
    "\\newcommand{\\vws}{\\vw_s}\n",
    "\\newcommand{\\vwt}{\\mathbf{\\tilde{w}}}\n",
    "\\newcommand{\\vWt}{\\mathbf{\\tilde{W}}}\n",
    "\\newcommand{\\vwh}{\\hat{\\vw}}\n",
    "\\newcommand{\\vx}{\\mathbf{x}}\n",
    "%\\newcommand{\\vx}{\\mathbf{x}}\n",
    "\\newcommand{\\vxt}{\\mathbf{\\tilde{x}}}\n",
    "\\newcommand{\\vy}{\\mathbf{y}}\n",
    "\\newcommand{\\vyt}{\\mathbf{\\tilde{y}}}\n",
    "\\newcommand{\\vz}{\\mathbf{z}}\n",
    "%\\newcommand{\\vzt}{\\mathbf{\\tilde{z}}}\n",
    "\n",
    "\n",
    "% Upper Roman (Matrices)\n",
    "\\newcommand{\\vA}{\\mathbf{A}}\n",
    "\\newcommand{\\vB}{\\mathbf{B}}\n",
    "\\newcommand{\\vC}{\\mathbf{C}}\n",
    "\\newcommand{\\vD}{\\mathbf{D}}\n",
    "\\newcommand{\\vE}{\\mathbf{E}}\n",
    "\\newcommand{\\vF}{\\mathbf{F}}\n",
    "\\newcommand{\\vG}{\\mathbf{G}}\n",
    "\\newcommand{\\vH}{\\mathbf{H}}\n",
    "\\newcommand{\\vI}{\\mathbf{I}}\n",
    "\\newcommand{\\vJ}{\\mathbf{J}}\n",
    "\\newcommand{\\vK}{\\mathbf{K}}\n",
    "\\newcommand{\\vL}{\\mathbf{L}}\n",
    "\\newcommand{\\vM}{\\mathbf{M}}\n",
    "\\newcommand{\\vMt}{\\mathbf{\\tilde{M}}}\n",
    "\\newcommand{\\vN}{\\mathbf{N}}\n",
    "\\newcommand{\\vO}{\\mathbf{O}}\n",
    "\\newcommand{\\vP}{\\mathbf{P}}\n",
    "\\newcommand{\\vQ}{\\mathbf{Q}}\n",
    "\\newcommand{\\vR}{\\mathbf{R}}\n",
    "\\newcommand{\\vS}{\\mathbf{S}}\n",
    "\\newcommand{\\vT}{\\mathbf{T}}\n",
    "\\newcommand{\\vU}{\\mathbf{U}}\n",
    "\\newcommand{\\vV}{\\mathbf{V}}\n",
    "\\newcommand{\\vW}{\\mathbf{W}}\n",
    "\\newcommand{\\vX}{\\mathbf{X}}\n",
    "%\\newcommand{\\vXs}{\\vX_{\\vs}}\n",
    "\\newcommand{\\vXs}{\\vX_{s}}\n",
    "\\newcommand{\\vXt}{\\mathbf{\\tilde{X}}}\n",
    "\\newcommand{\\vY}{\\mathbf{Y}}\n",
    "\\newcommand{\\vZ}{\\mathbf{Z}}\n",
    "\\newcommand{\\vZt}{\\mathbf{\\tilde{Z}}}\n",
    "\\newcommand{\\vzt}{\\mathbf{\\tilde{z}}}\n",
    "\n",
    "\n",
    "%%%%\n",
    "\\newcommand{\\hidden}{\\vz}\n",
    "\\newcommand{\\hid}{\\hidden}\n",
    "\\newcommand{\\observed}{\\vy}\n",
    "\\newcommand{\\obs}{\\observed}\n",
    "\\newcommand{\\inputs}{\\vu}\n",
    "\\newcommand{\\input}{\\inputs}\n",
    "\n",
    "\\newcommand{\\hmmTrans}{\\vA}\n",
    "\\newcommand{\\hmmObs}{\\vB}\n",
    "\\newcommand{\\hmmInit}{\\vpi}\n",
    "\n",
    "\n",
    "\\newcommand{\\ldsDyn}{\\vA}\n",
    "\\newcommand{\\ldsObs}{\\vC}\n",
    "\\newcommand{\\ldsDynIn}{\\vB}\n",
    "\\newcommand{\\ldsObsIn}{\\vD}\n",
    "\\newcommand{\\ldsDynNoise}{\\vQ}\n",
    "\\newcommand{\\ldsObsNoise}{\\vR}\n",
    "\n",
    "\\newcommand{\\ssmDynFn}{f}\n",
    "\\newcommand{\\ssmObsFn}{h}\n",
    "\n",
    "\n",
    "%%%\n",
    "\\newcommand{\\gauss}{\\mathcal{N}}\n",
    "\n",
    "\\newcommand{\\diag}{\\mathrm{diag}}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta-data does not work yet in VScode\n",
    "# https://github.com/microsoft/vscode-jupyter/issues/1121\n",
    "\n",
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-cell\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "### Install necessary libraries\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "except:\n",
    "    # For cuda version, see https://github.com/google/jax#installation\n",
    "    %pip install --upgrade \"jax[cpu]\" \n",
    "    import jax\n",
    "\n",
    "try:\n",
    "    import distrax\n",
    "except:\n",
    "    %pip install --upgrade  distrax\n",
    "    import distrax\n",
    "\n",
    "try:\n",
    "    import jsl\n",
    "except:\n",
    "    %pip install git+https://github.com/probml/jsl\n",
    "    import jsl\n",
    "\n",
    "#try:\n",
    "#    import ssm_jax\n",
    "##except:\n",
    "#    %pip install git+https://github.com/probml/ssm-jax\n",
    "#    import ssm_jax\n",
    "\n",
    "try:\n",
    "    import rich\n",
    "except:\n",
    "    %pip install rich\n",
    "    import rich\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-cell\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "### Import standard libraries\n",
    "\n",
    "import abc\n",
    "from dataclasses import dataclass\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "from typing import Any, Callable, NamedTuple, Optional, Union, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import lax, vmap, jit, grad\n",
    "from jax.scipy.special import logit\n",
    "from jax.nn import softmax\n",
    "from functools import partial\n",
    "from jax.random import PRNGKey, split\n",
    "\n",
    "import inspect\n",
    "import inspect as py_inspect\n",
    "import rich\n",
    "from rich import inspect as r_inspect\n",
    "from rich import print as r_print\n",
    "\n",
    "def print_source(fname):\n",
    "    r_print(py_inspect.getsource(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:forwards)=\n",
    "# HMM filtering (forwards algorithm)\n",
    "\n",
    "\n",
    "The  **Bayes filter** is an algorithm for recursively computing\n",
    "the belief state\n",
    "$p(\\hidden_t|\\obs_{1:t})$ given\n",
    "the prior belief from the previous step,\n",
    "$p(\\hidden_{t-1}|\\obs_{1:t-1})$,\n",
    "the new observation $\\obs_t$,\n",
    "and the model.\n",
    "This can be done using **sequential Bayesian updating**.\n",
    "For a dynamical model, this reduces to the\n",
    "**predict-update** cycle described below.\n",
    "\n",
    "\n",
    "The **prediction step** is just the **Chapman-Kolmogorov equation**:\n",
    "```{math}\n",
    "p(\\hidden_t|\\obs_{1:t-1})\n",
    "= \\int p(\\hidden_t|\\hidden_{t-1}) p(\\hidden_{t-1}|\\obs_{1:t-1}) d\\hidden_{t-1}\n",
    "```\n",
    "The prediction step computes\n",
    "the one-step-ahead predictive distribution\n",
    "for the latent state, which updates\n",
    "the posterior from the previous time step into the prior\n",
    "for the current step.\n",
    "\n",
    "\n",
    "The **update step**\n",
    "is just Bayes rule:\n",
    "```{math}\n",
    "p(\\hidden_t|\\obs_{1:t}) = \\frac{1}{Z_t}\n",
    "p(\\obs_t|\\hidden_t) p(\\hidden_t|\\obs_{1:t-1})\n",
    "```\n",
    "where the normalization constant is\n",
    "```{math}\n",
    "Z_t = \\int p(\\obs_t|\\hidden_t) p(\\hidden_t|\\obs_{1:t-1}) d\\hidden_{t}\n",
    "= p(\\obs_t|\\obs_{1:t-1})\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When the latent states $\\hidden_t$ are discrete, as in HMM,\n",
    "the above integrals become sums.\n",
    "In particular, suppose we define\n",
    "the belief state as $\\alpha_t(j) \\defeq p(\\hidden_t=j|\\obs_{1:t})$,\n",
    "the local evidence as $\\lambda_t(j) \\defeq p(\\obs_t|\\hidden_t=j)$,\n",
    "and the transition matrix\n",
    "$A(i,j)  = p(\\hidden_t=j|\\hidden_{t-1}=i)$.\n",
    "Then the predict step becomes\n",
    "```{math}\n",
    ":label: eqn:predictiveHMM\n",
    "\\alpha_{t|t-1}(j) \\defeq p(\\hidden_t=j|\\obs_{1:t-1})\n",
    " = \\sum_i \\alpha_{t-1}(i) A(i,j)\n",
    "```\n",
    "and the update step becomes\n",
    "```{math}\n",
    ":label: eqn:fwdsEqn\n",
    "\\alpha_t(j)\n",
    "= \\frac{1}{Z_t} \\lambda_t(j) \\alpha_{t|t-1}(j)\n",
    "= \\frac{1}{Z_t} \\lambda_t(j) \\left[\\sum_i \\alpha_{t-1}(i) A(i,j)  \\right]\n",
    "```\n",
    "where\n",
    "the  normalization constant for each time step is given by\n",
    "```{math}\n",
    ":label: eqn:HMMZ\n",
    "\\begin{align}\n",
    "Z_t \\defeq p(\\obs_t|\\obs_{1:t-1})\n",
    "&=  \\sum_{j=1}^K p(\\obs_t|\\hidden_t=j)  p(\\hidden_t=j|\\obs_{1:t-1}) \\\\\n",
    "&=  \\sum_{j=1}^K \\lambda_t(j) \\alpha_{t|t-1}(j)\n",
    "\\end{align}\n",
    "```\n",
    "\n",
    "Since all the quantities are finite length vectors and matrices,\n",
    "we can write the update equation\n",
    "in matrix-vector notation as follows:\n",
    "```{math}\n",
    "\\valpha_t =\\text{normalize}\\left(\n",
    "\\vlambda_t \\dotstar  (\\vA^{\\trans} \\valpha_{t-1}) \\right)\n",
    "\\label{eqn:fwdsAlgoMatrixForm}\n",
    "```\n",
    "where $\\dotstar$ represents\n",
    "elementwise vector multiplication,\n",
    "and the $\\text{normalize}$ function just ensures its argument sums to one.\n",
    "\n",
    "In {ref}(sec:casino-inference)\n",
    "we illustrate\n",
    "filtering for the casino HMM,\n",
    "applied to a random sequence $\\obs_{1:T}$ of length $T=300$.\n",
    "In blue, we plot the probability that the dice is in the loaded (vs fair) state,\n",
    "based on the evidence seen so far.\n",
    "The gray bars indicate time intervals during which the generative\n",
    "process actually switched to the loaded dice.\n",
    "We see that the probability generally increases in the right places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a JAX implementation of the forwards algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">@jit\n",
       "def hmm_forwards_jax<span style=\"font-weight: bold\">(</span>params, obs_seq, <span style=\"color: #808000; text-decoration-color: #808000\">length</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>:\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">''</span>'\n",
       "    Calculates a belief state\n",
       "\n",
       "    Parameters\n",
       "    ----------\n",
       "    params : HMMJax\n",
       "        Hidden Markov Model\n",
       "\n",
       "    obs_seq: array<span style=\"font-weight: bold\">(</span>seq_len<span style=\"font-weight: bold\">)</span>\n",
       "        History of observable events\n",
       "\n",
       "    Returns\n",
       "    -------\n",
       "    * float\n",
       "        The loglikelihood giving log<span style=\"font-weight: bold\">(</span>p<span style=\"font-weight: bold\">(</span>x|model<span style=\"font-weight: bold\">))</span>\n",
       "\n",
       "    * array<span style=\"font-weight: bold\">(</span>seq_len, n_hidden<span style=\"font-weight: bold\">)</span> :\n",
       "        All alpha values found for each sample\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">''</span>'\n",
       "    seq_len = len<span style=\"font-weight: bold\">(</span>obs_seq<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "    if length is <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>:\n",
       "        length = seq_len\n",
       "\n",
       "    trans_mat, obs_mat, init_dist = params.trans_mat, params.obs_mat, params.init_dist\n",
       "\n",
       "    trans_mat = jnp.array<span style=\"font-weight: bold\">(</span>trans_mat<span style=\"font-weight: bold\">)</span>\n",
       "    obs_mat = jnp.array<span style=\"font-weight: bold\">(</span>obs_mat<span style=\"font-weight: bold\">)</span>\n",
       "    init_dist = jnp.array<span style=\"font-weight: bold\">(</span>init_dist<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "    n_states, n_obs = obs_mat.shape\n",
       "\n",
       "    def scan_fn<span style=\"font-weight: bold\">(</span>carry, t<span style=\"font-weight: bold\">)</span>:\n",
       "        <span style=\"font-weight: bold\">(</span>alpha_prev, log_ll_prev<span style=\"font-weight: bold\">)</span> = carry\n",
       "        alpha_n = jnp.where<span style=\"font-weight: bold\">(</span>t &lt; length,\n",
       "                            obs_mat<span style=\"font-weight: bold\">[</span>:, obs_seq<span style=\"font-weight: bold\">]</span> * <span style=\"font-weight: bold\">(</span>alpha_prev<span style=\"font-weight: bold\">[</span>:, <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">]</span> * \n",
       "trans_mat<span style=\"font-weight: bold\">)</span>.sum<span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">axis</span>=<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
       "                            jnp.zeros_like<span style=\"font-weight: bold\">(</span>alpha_prev<span style=\"font-weight: bold\">))</span>\n",
       "\n",
       "        alpha_n, cn = normalize<span style=\"font-weight: bold\">(</span>alpha_n<span style=\"font-weight: bold\">)</span>\n",
       "        carry = <span style=\"font-weight: bold\">(</span>alpha_n, jnp.log<span style=\"font-weight: bold\">(</span>cn<span style=\"font-weight: bold\">)</span> + log_ll_prev<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "        return carry, alpha_n\n",
       "\n",
       "    # initial belief state\n",
       "    alpha_0, c0 = normalize<span style=\"font-weight: bold\">(</span>init_dist * obs_mat<span style=\"font-weight: bold\">[</span>:, obs_seq<span style=\"font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]])</span>\n",
       "\n",
       "    # setup scan loop\n",
       "    init_state = <span style=\"font-weight: bold\">(</span>alpha_0, jnp.log<span style=\"font-weight: bold\">(</span>c0<span style=\"font-weight: bold\">))</span>\n",
       "    ts = jnp.arange<span style=\"font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span>, seq_len<span style=\"font-weight: bold\">)</span>\n",
       "    carry, alpha_hist = lax.scan<span style=\"font-weight: bold\">(</span>scan_fn, init_state, ts<span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "    # post-process\n",
       "    alpha_hist = jnp.vstack<span style=\"font-weight: bold\">()</span>\n",
       "    <span style=\"font-weight: bold\">(</span>alpha_final, log_ll<span style=\"font-weight: bold\">)</span> = carry\n",
       "    return log_ll, alpha_hist\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fe75997dfa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jsl.hmm.hmm_lib as hmm_lib\n",
    "print_source(hmm_lib.hmm_forwards_jax)\n",
    "#https://github.com/probml/JSL/blob/main/jsl/hmm/hmm_lib.py#L189\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6407c60499271029b671b4ff687c4ed4626355c45fd34c44476827f4be42c4d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('spyder-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}